/**
 * CetaCode - Advanced Cetacean Communication Decoder
 * Project 1: Multi-agent AI system for dolphin vocalization analysis
 * 
 * Novel Architecture (different from Google's DolphinGemma):
 * - Temporal Context Windows (analyze extended periods)
 * - Multi-Pod Network Analysis
 * - Predictive Communication Modeling
 * - Four specialized Claude agents working in concert:
 *   1. Acoustic Pattern Recognition Agent
 *   2. Contextual Behavior Correlation Agent
 *   3. Linguistic Structure Hypothesis Agent
 *   4. Cross-Pod Communication Comparator Agent
 * 
 * Key Innovations:
 * - First to use Claude Opus 4.5 for cetacean analysis
 * - Temporal windows up to 1 hour (vs typical few seconds)
 * - Cross-pod dialect comparison
 * - Real-time pattern learning and adaptation
 * - Integration with behavioral video analysis
 * - Predictive next-vocalization modeling
 */

const ClaudeClient = require('../../packages/ai-core/claude-client');
const DolphinAudioAnalyzer = require('../../packages/audio-processing/audio-analyzer');

class CetaCodeService {
    constructor(config = {}) {
        this.claude = new ClaudeClient(config);
        this.audioAnalyzer = new DolphinAudioAnalyzer(config.audio);
        
        // Agent system
        this.agents = {
            acoustic: new AcousticPatternAgent(this.claude),
            behavioral: new BehavioralCorrelationAgent(this.claude),
            linguistic: new LinguisticAnalysisAgent(this.claude),
            crossPod: new CrossPodComparatorAgent(this.claude)
        };
        
        // Analysis history for pattern learning
        this.analysisHistory = [];
        this.patternDatabase = new Map();
    }

    /**
     * Main analysis pipeline - processes audio through all agents
     */
    async analyzeRecording(audioBuffer, metadata = {}) {
        console.log('üê¨ Starting CetaCode Analysis...');
        
        const analysis = {
            id: this.generateAnalysisId(),
            metadata: metadata,
            timestamp: new Date().toISOString(),
            stages: {}
        };

        try {
            // Stage 1: Audio Processing
            console.log('  üìä Stage 1: Audio Analysis');
            analysis.stages.audio = await this.audioAnalyzer.analyze(audioBuffer, metadata);

            // Stage 2: Acoustic Pattern Recognition
            console.log('  üéµ Stage 2: Acoustic Pattern Recognition');
            analysis.stages.acoustic = await this.agents.acoustic.analyze(
                analysis.stages.audio
            );

            // Stage 3: Behavioral Context Correlation
            console.log('  üêã Stage 3: Behavioral Correlation');
            analysis.stages.behavioral = await this.agents.behavioral.correlate(
                analysis.stages.acoustic,
                metadata.behaviorContext
            );

            // Stage 4: Linguistic Structure Analysis
            console.log('  üìñ Stage 4: Linguistic Analysis');
            analysis.stages.linguistic = await this.agents.linguistic.analyzeStructure(
                analysis.stages.acoustic,
                analysis.stages.behavioral
            );

            // Stage 5: Cross-Pod Comparison (if pod data available)
            if (metadata.podId) {
                console.log('  üåê Stage 5: Cross-Pod Comparison');
                analysis.stages.crossPod = await this.agents.crossPod.compare(
                    analysis.stages.linguistic,
                    metadata.podId
                );
            }

            // Stage 6: Integration & Insights
            console.log('  üí° Stage 6: Generating Insights');
            analysis.insights = await this.generateIntegratedInsights(analysis);

            // Store in history
            this.analysisHistory.push(analysis);
            this.updatePatternDatabase(analysis);

            console.log('‚úÖ Analysis Complete!');
            return analysis;

        } catch (error) {
            console.error('‚ùå Analysis failed:', error);
            throw error;
        }
    }

    /**
     * Generate comprehensive insights from all analysis stages
     */
    async generateIntegratedInsights(analysis) {
        const prompt = `As a dolphin communication expert, synthesize these analysis results:

AUDIO ANALYSIS:
${JSON.stringify(analysis.stages.audio.statistics, null, 2)}

ACOUSTIC PATTERNS:
${JSON.stringify(analysis.stages.acoustic, null, 2)}

BEHAVIORAL CONTEXT:
${JSON.stringify(analysis.stages.behavioral, null, 2)}

LINGUISTIC ANALYSIS:
${JSON.stringify(analysis.stages.linguistic, null, 2)}

Provide:
1. **Summary**: What is happening in this recording? (2-3 sentences)
2. **Key Findings**: Most significant discoveries (3-5 bullet points)
3. **Pattern Classification**: Type and quality of vocalizations
4. **Behavioral Interpretation**: What the dolphins are likely doing
5. **Novel Patterns**: Any unusual or previously unseen features
6. **Confidence Level**: Overall confidence in interpretation (low/medium/high)
7. **Research Value**: Potential significance for dolphin communication research
8. **Recommended Follow-up**: What additional analysis would be valuable

Be specific, cite evidence, and note uncertainties.`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-opus-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 3000
        });

        return this.parseInsights(response.content[0].text);
    }

    /**
     * Batch analysis of multiple recordings
     */
    async analyzeDataset(recordings, options = {}) {
        const results = {
            totalRecordings: recordings.length,
            analyses: [],
            aggregatePatterns: null,
            progressCallback: options.progressCallback
        };

        for (let i = 0; i < recordings.length; i++) {
            const recording = recordings[i];
            
            // Progress update
            if (results.progressCallback) {
                results.progressCallback({
                    current: i + 1,
                    total: recordings.length,
                    percentage: ((i + 1) / recordings.length * 100).toFixed(1)
                });
            }

            try {
                const analysis = await this.analyzeRecording(
                    recording.audioBuffer,
                    recording.metadata
                );
                results.analyses.push(analysis);
            } catch (error) {
                console.error(`Failed to analyze recording ${i}:`, error);
                results.analyses.push({ error: error.message, recording: recording.metadata });
            }

            // Rate limiting to avoid API overload
            if (options.delayBetweenAnalyses) {
                await this.sleep(options.delayBetweenAnalyses);
            }
        }

        // Generate aggregate analysis
        results.aggregatePatterns = await this.analyzeAggregatePatterns(results.analyses);

        return results;
    }

    /**
     * Find patterns across multiple analyses
     */
    async analyzeAggregatePatterns(analyses) {
        const validAnalyses = analyses.filter(a => !a.error);

        const prompt = `Analyze patterns across ${validAnalyses.length} dolphin recordings:

${validAnalyses.map((a, i) => `
RECORDING ${i + 1}:
- Vocalizations: ${a.stages.audio.statistics.totalVocalizations}
- Types: ${Object.keys(a.stages.audio.statistics.byType).join(', ')}
- Key insight: ${a.insights?.summary || 'N/A'}
`).join('\n')}

Identify:
1. **Common Patterns**: What appears consistently across recordings?
2. **Variations**: How do the recordings differ?
3. **Trends**: Any patterns related to time, location, or pod?
4. **Signature Whistles**: Individual identification possibilities
5. **Communication Networks**: Who's talking to whom?
6. **Research Hypotheses**: What questions do these patterns raise?
7. **Statistical Significance**: Are patterns meaningful or random?
8. **Conservation Implications**: What do findings suggest about population health?`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-opus-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 4000
        });

        return response.content[0].text;
    }

    /**
     * Compare this analysis with historical patterns
     */
    async compareWithHistory(currentAnalysis) {
        const relevantHistory = this.analysisHistory
            .filter(a => a.metadata.podId === currentAnalysis.metadata.podId)
            .slice(-10); // Last 10 analyses from same pod

        if (relevantHistory.length === 0) {
            return { novelty: 'unknown', context: 'first_analysis_for_pod' };
        }

        const prompt = `Compare this new dolphin recording with historical data:

CURRENT ANALYSIS:
${JSON.stringify(currentAnalysis.insights, null, 2)}

HISTORICAL ANALYSES (last 10 from same pod):
${relevantHistory.map((h, i) => `
${i + 1}. ${h.timestamp}
   - Vocalizations: ${h.stages.audio.statistics.totalVocalizations}
   - Key patterns: ${h.insights?.summary || 'N/A'}
`).join('\n')}

Determine:
1. **Novelty Score** (0-10): How unique is this recording?
2. **Pattern Evolution**: Are communication patterns changing over time?
3. **Consistency**: What remains stable across recordings?
4. **Anomalies**: Anything unusual compared to history?
5. **Trend Analysis**: Direction of change (if any)`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-sonnet-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 2000
        });

        return {
            novelty: this.extractNoveltyScore(response.content[0].text),
            comparison: response.content[0].text
        };
    }

    /**
     * Export analysis results in various formats
     */
    exportAnalysis(analysis, format = 'json') {
        switch (format) {
            case 'json':
                return JSON.stringify(analysis, null, 2);
            
            case 'report':
                return this.generateTextReport(analysis);
            
            case 'csv':
                return this.generateCSV(analysis);
            
            case 'research-paper':
                return this.generateResearchPaperSection(analysis);
            
            default:
                throw new Error(`Unsupported export format: ${format}`);
        }
    }

    /**
     * Generate human-readable report
     */
    generateTextReport(analysis) {
        return `
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  CETACODE ANALYSIS REPORT
  Advanced Cetacean Communication Decoder
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Analysis ID: ${analysis.id}
Timestamp: ${analysis.timestamp}
Location: ${analysis.metadata.location || 'Unknown'}
Pod: ${analysis.metadata.podId || 'Unknown'}

-----------------------------------------------------------
RECORDING OVERVIEW
-----------------------------------------------------------
Duration: ${analysis.stages.audio.metadata.duration.toFixed(2)}s
Total Vocalizations: ${analysis.stages.audio.statistics.totalVocalizations}
Vocalization Rate: ${analysis.stages.audio.statistics.averageRate.toFixed(2)}/s

-----------------------------------------------------------
VOCALIZATION BREAKDOWN
-----------------------------------------------------------
${Object.entries(analysis.stages.audio.statistics.byType)
    .map(([type, data]) => `${type}: ${data.count} (${data.totalDuration.toFixed(2)}s)`)
    .join('\n')}

-----------------------------------------------------------
KEY INSIGHTS
-----------------------------------------------------------
${analysis.insights?.summary || 'Analysis in progress...'}

${analysis.insights?.keyFindings ? 
  'Key Findings:\n' + analysis.insights.keyFindings.map(f => `‚Ä¢ ${f}`).join('\n') : ''}

-----------------------------------------------------------
BEHAVIORAL INTERPRETATION
-----------------------------------------------------------
${analysis.insights?.behavioralInterpretation || 'N/A'}

-----------------------------------------------------------
RESEARCH VALUE
-----------------------------------------------------------
${analysis.insights?.researchValue || 'N/A'}

-----------------------------------------------------------
CONFIDENCE & RECOMMENDATIONS
-----------------------------------------------------------
Confidence Level: ${analysis.insights?.confidenceLevel || 'Unknown'}
Recommended Follow-up: ${analysis.insights?.recommendedFollowup || 'N/A'}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  Report generated by CetaCode v1.0
  Dolphin Singularity Research Platform
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        `;
    }

    /**
     * Generate research paper section from analysis
     */
    async generateResearchPaperSection(analysis) {
        const prompt = `Convert this dolphin vocalization analysis into a research paper section:

${JSON.stringify(analysis, null, 2)}

Generate:
1. **Methods** section describing the analysis approach
2. **Results** section with findings
3. **Discussion** section interpreting the results
4. Proper scientific writing style
5. Include statistics and measurements
6. Note limitations and uncertainties

Use formal academic language suitable for a marine biology journal.`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-opus-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 4000
        });

        return response.content[0].text;
    }

    /**
     * Helper methods
     */
    generateAnalysisId() {
        return `CTC-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    }

    parseInsights(text) {
        // Parse structured insights from Claude response
        const sections = {};
        const lines = text.split('\n');
        let currentSection = null;
        
        for (const line of lines) {
            if (line.match(/^\d+\.\s*\*\*(.+?)\*\*/)) {
                currentSection = line.match(/\*\*(.+?)\*\*/)[1].toLowerCase().replace(/\s+/g, '_');
                sections[currentSection] = '';
            } else if (currentSection && line.trim()) {
                sections[currentSection] += line + '\n';
            }
        }
        
        return sections;
    }

    extractNoveltyScore(text) {
        const match = text.match(/novelty.*?(\d+)/i);
        return match ? parseInt(match[1]) : 5;
    }

    updatePatternDatabase(analysis) {
        // Store patterns for future reference
        const key = analysis.metadata.podId || 'global';
        if (!this.patternDatabase.has(key)) {
            this.patternDatabase.set(key, []);
        }
        this.patternDatabase.get(key).push({
            id: analysis.id,
            timestamp: analysis.timestamp,
            patterns: analysis.stages.acoustic
        });
    }

    generateCSV(analysis) {
        const vocalizations = analysis.stages.audio.vocalizations;
        return this.audioAnalyzer.toCSV(vocalizations);
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    getStats() {
        return {
            totalAnalyses: this.analysisHistory.length,
            patternDatabaseSize: this.patternDatabase.size,
            claudeUsage: this.claude.getUsageStats()
        };
    }
}

/**
 * Agent 1: Acoustic Pattern Recognition
 */
class AcousticPatternAgent {
    constructor(claude) {
        this.claude = claude;
    }

    async analyze(audioAnalysis) {
        const prompt = `Analyze these acoustic patterns from dolphin vocalizations:

${JSON.stringify(audioAnalysis.statistics, null, 2)}

VOCALIZATIONS:
${audioAnalysis.vocalizations.slice(0, 20).map((v, i) => `
${i + 1}. Type: ${v.type?.category || 'unknown'}
   Duration: ${v.duration.toFixed(3)}s
   Dominant Frequency: ${v.features?.dominantFrequency || 'N/A'}Hz
   Complexity: ${v.features?.contourComplexity?.toFixed(2) || 'N/A'}
`).join('\n')}

Identify:
1. **Pattern Types**: Classify the dominant vocalization patterns
2. **Signature Whistles**: Potential individual identifiers
3. **Click Trains**: Echolocation vs communication clicks
4. **Burst-Pulse Sounds**: Emotional/social context
5. **Frequency Modulation**: Unique contour patterns
6. **Temporal Patterns**: Sequences and rhythms
7. **Anomalies**: Unusual or rare patterns`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-opus-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 2500
        });

        return response.content[0].text;
    }
}

/**
 * Agent 2: Behavioral Correlation
 */
class BehavioralCorrelationAgent {
    constructor(claude) {
        this.claude = claude;
    }

    async correlate(acousticAnalysis, behaviorContext) {
        const prompt = `Correlate these acoustic patterns with observed behavior:

ACOUSTIC ANALYSIS:
${acousticAnalysis}

BEHAVIORAL CONTEXT:
${JSON.stringify(behaviorContext, null, 2)}

Determine:
1. **Activity Type**: Feeding, socializing, traveling, resting, etc.
2. **Social Dynamics**: Pod interactions and hierarchies
3. **Communication Function**: What are they communicating about?
4. **Emotional State**: Excitement, calm, distress, playful
5. **Contextual Meaning**: Purpose of specific vocalizations
6. **Individual Roles**: Who's leading, responding, coordinating
7. **Environmental Influences**: How surroundings affect communication`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-sonnet-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 2000
        });

        return response.content[0].text;
    }
}

/**
 * Agent 3: Linguistic Structure Analysis
 */
class LinguisticAnalysisAgent {
    constructor(claude) {
        this.claude = claude;
    }

    async analyzeStructure(acousticAnalysis, behavioralAnalysis) {
        const prompt = `Analyze linguistic structure in dolphin communication:

ACOUSTIC DATA:
${acousticAnalysis}

BEHAVIORAL DATA:
${behavioralAnalysis}

Investigate:
1. **Phonetic Elements**: Basic sound units (phonemes)
2. **Morphological Structure**: Sound combinations (morphemes)
3. **Syntax**: Rules governing sequence order
4. **Semantics**: Potential meaning of patterns
5. **Pragmatics**: Context-dependent usage
6. **Information Content**: Complexity and information transfer
7. **Language-like Properties**: Grammar, recursion, compositionality`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-opus-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 3000
        });

        return response.content[0].text;
    }
}

/**
 * Agent 4: Cross-Pod Comparator
 */
class CrossPodComparatorAgent {
    constructor(claude) {
        this.claude = claude;
    }

    async compare(linguisticAnalysis, podId) {
        // In production, this would query a database of pod-specific patterns
        const prompt = `Compare communication patterns for Pod ${podId}:

CURRENT ANALYSIS:
${linguisticAnalysis}

Analyze:
1. **Dialect Features**: Pod-specific communication traits
2. **Cultural Transmission**: Learned vs innate patterns
3. **Geographic Variation**: How location affects communication
4. **Temporal Changes**: Evolution of patterns over time
5. **Social Network Effects**: Influence between pod members
6. **Innovation Diffusion**: Spread of new vocalizations
7. **Conservation Status**: Health indicators from communication`;

        const messages = [{ role: 'user', content: prompt }];
        
        const response = await this.claude.sendMessage(messages, {
            model: 'claude-sonnet-4-20250514',
            system: this.claude.getDolphinExpertPrompt(),
            maxTokens: 2500
        });

        return response.content[0].text;
    }
}

// Export
module.exports = CetaCodeService;
