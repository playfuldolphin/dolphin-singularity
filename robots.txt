# Robots.txt for DolphinSingularity.org
# Last updated: February 2026

# Allow all beneficial crawlers
User-agent: *
Allow: /
Crawl-delay: 1

# Disallow access to internal directories and old files
Disallow: /.git/
Disallow: /.github/
Disallow: /api/
Disallow: /packages/
Disallow: /services/
Disallow: /*-old.html
Disallow: /*-backup.html
Disallow: /*.md

# Explicitly allow important content
Allow: /blog/
Allow: /images/
Allow: /css/
Allow: /js/
Allow: /*.css
Allow: /*.js
Allow: /manifest.json
Allow: /sw.js

# Sitemap location
Sitemap: https://dolphinsingularity.org/sitemap.xml

# Humans file
# See who built this at: https://dolphinsingularity.org/humans.txt

# Specific crawler instructions for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 0

User-agent: Googlebot-Image
Allow: /images/

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 1

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 1

# Social media crawlers
User-agent: facebot
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

# Block aggressive SEO/scraper bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Crawl-delay: 10

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /